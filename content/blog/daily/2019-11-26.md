---
title: 2019-11-26
date: 2019-11-26
---
# Elasticsearch 기본 정리

> 프로젝트를 진행하며 Elasticsearch를 사용해야 할 일이 생겼습니다. 이에 따라 기본적인 사용 방법을 파악하기 위해 공식 문서의 get started 내용을 정리하였습니다. 

### Elastic Stack

과거 ELK 스택으로 불리던 제품 묶음이 이제는 Elastic Stack이라는 제품군으로 통일

### DB등과 어떻게 연결해야 하는지

다양한 방법들이 존재한다. 그중 많이 쓰이는 방법은 Logstash를 사용하는 방법이다.

input source(DB)와 한개 이상의 output sinks(Elastic Search) 중간에 연결고리로 작용하는 pipeline을 생성한다.

Logstash는 데이터를 연결하기 위한 다양한 source 와 sink의 종류에 대응하여 라이브러리를 제공한다. 

mongodb의 경우에는 output(sink)에 대한 라이브러리가 제공되지만, input으로서는 제공되지 않는다

input 리스트

[https://www.elastic.co/guide/en/logstash/current/input-plugins.html](https://www.elastic.co/guide/en/logstash/current/input-plugins.html)

output 리스트

[https://www.elastic.co/guide/en/logstash/current/output-plugins.html](https://www.elastic.co/guide/en/logstash/current/output-plugins.html)

### Elasticsearch REST API의 3가지 query방법

출처: [https://www.elastic.co/guide/en/elasticsearch/reference/current/search-analyze.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-analyze.html)

- structured queries
- full text queries
- complex queries

**structured queries**

- SQL에서 구성 하는것과 유사한 방법

> you could search the `gender` and `age` fields in your `employee index` and sort the matches by the `hire_date` field

**Full-text queries**

> find all documents that match the query string and return them sorted by relevance

- relevance는 how good a match they are for your search terms.

**complex queries**

위 **structured queries**와 **full text queries** 를 합친 방식

**추가적으로,**

또한 다음과 같은 기능을 제공한다

phrase searches, similarity searches, and prefix searches, and get autocomplete suggestions

또한, 지리적 query와 대수적인 query 모두를 고성능으로 제공한다.

위 모든 query는 Elasticsearch의 포괄적인 JSON스타일의 쿼리(Query DSL)을 통해 사용할 수 있다.

이 뿐만 아니라, SQL형태의 query도 적용 가능하다.

# docker & Elasticsearch

## 설치

출처: [https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html)

두가지 방법이 존재한다. 

나의 경우에는 간단한 테스트를 위한 환경 구성이므로 single node도 무방해 보인다.

    # docker image pull
    docker pull docker.elastic.co/elasticsearch/elasticsearch:7.4.2
    # docker run
    docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.4.2

이렇게 올라간 엘라스틱서치를 확인하기 위해 다음과 같은 명령어 타입

    ╰─ curl -X GET "localhost:9200/_cat/health?v"
    
    # 결과
    epoch      timestamp cluster        status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
    1574745447 05:17:27  docker-cluster green           1         1      0   0    0    0        0             0                  -                100.0%

위의 예시에서 보이듯이, elasticsearch는 restful api로 명령어를 수행 하는듯 하다. 

## 사용법

Rest api로 설정이 가능하니, 데이터 주입이 가능함도 당연하다.

### 등록

    curl -X PUT "localhost:9200/customer/_doc/1?pretty" -H \
    'Content-Type: application/json' -d'
    {
      "name": "John Doe"
    }
    '
    
    # 결과
    {
      "_index" : "customer",
      "_type" : "_doc",
      "_id" : "1",
      "_version" : 1,
      "result" : "created",
      "_shards" : {
        "total" : 2,
        "successful" : 1,
        "failed" : 0
      },
      "_seq_no" : 0,
      "_primary_term" : 1
    }

### 조회

    curl -X GET "localhost:9200/customer/_doc/1?pretty"
    
    # 결과
    {
      "_index" : "customer",
      "_type" : "_doc",
      "_id" : "1",
      "_version" : 1,
      "_seq_no" : 0,
      "_primary_term" : 1,
      "found" : true,
      "_source" : {
        "name" : "John Doe"
      }
    }

### 벌크 주입

    curl -H "Content-Type: application/json" \
    -XPOST "localhost:9200/bank/_bulk?pretty&refresh" \
    --data-binary "@accounts.json"
    
    # 결과
    
    ...
    {
          "index" : {
            "_index" : "bank",
            "_type" : "_doc",
            "_id" : "717",
            "_version" : 1,
            "result" : "created",
            "forced_refresh" : true,
            "_shards" : {
              "total" : 2,
              "successful" : 1,
              "failed" : 0
            },
            "_seq_no" : 943,
            "_primary_term" : 1,
            "status" : 201
          }
        },
    ...

신기하게도, 상대경로나 절대경로가 아닌 `@` 를 파일 앞에 두어야 한다. 

`./accounts.json` 으로 해보니 에러가 뜬다.

### index들 조회

    curl "localhost:9200/_cat/indices?v"
    
    # 결과
    health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size
    yellow open   bank     Vi8pnBZRQHaZY5J2NrdM0g   1   1       1000            0    414.2kb        414.2kb
    yellow open   customer aZHN_XWAQjC0j_W1yiYLRg   1   1          1            0      3.5kb          3.5kb

정상적으로 1000개의 bank정보가 주입 되었음을 확인할 수 있다. 

### 검색

    curl -X GET "localhost:9200/bank/_search?pretty" \
    -H 'Content-Type: application/json' -d'
    {
      "query": { "match_all": {} },
      "sort": [
        { "account_number": "asc" }
      ]
    }
    '
    
    # 결과
    {
      "took" : 384,
      "timed_out" : false,
      "_shards" : {
        "total" : 1,
        "successful" : 1,
        "skipped" : 0,
        "failed" : 0
      },
      "hits" : {
        "total" : {
          "value" : 1000,
          "relation" : "eq"
        },
        "max_score" : null,
        "hits" : [
          {
            "_index" : "bank",
            "_type" : "_doc",
            "_id" : "0",
            "_score" : null,
            "_source" : {
              "account_number" : 0,
              "balance" : 16623,
              "firstname" : "Bradshaw",
              "lastname" : "Mckenzie",
              "age" : 29,
              "gender" : "F",
              "address" : "244 Columbus Place",
              "employer" : "Euron",
              "email" : "bradshawmckenzie@euron.com",
              "city" : "Hobucken",
              "state" : "CO"
            },
            "sort" : [
              0
            ]
          },
    ... 9 more

기본적으로, hits의 배열(검색에대한 결과)은 검색 조건에 맞는 첫 10개의 documents를 포한한다.

**이 응답 JSON에는 결과값과 다음과 같은 정보를 포함하고 있다.** 

- took : query를 위해 소요된 시간. milliseconds
- timed_out: 검색 요청이 시간 초과가 되었는지 여부 확인
- _shards: 얼마나 많은 수의 shard가 검색되었는지, 그중 몇개의 shard가 성공/실패/건너띄었는지 의 정보
- max_score: 유사한 document중 가장 높은 점수
- hits.total.value: 얼마나 많은 수의 document가 조건과 부합하였는지
- hits.sort: 정렬 포지션 (관련 점수로 정렬되지 않았을 경우)
- hits._score: document의 유사 점수 (match_all를 사용시에 사용 불가)

다음과 같이 sort를 제한할 수 있다.

    curl -X GET "localhost:9200/bank/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "query": { "match_all": {} },
      "sort": [
        { "account_number": "asc" }
      ],
      "from": 10,
      "size": 10
    }
    '

또한, 다음과 같이 특정 문구를 검색할 수 있다. 

이 경우에, elasticsearch의 점수 알고리즘에 의해서 score를 측정하고, 가장 높은 점수 순으로 정렬된다.

    curl -X GET "localhost:9200/bank/_search?pretty" \
    -H 'Content-Type: application/json' -d'
    {
      "query": { "match": { "address": "mill lane" } }
    }
    '

위의 경우에는, mill와  lane을 포함하는 document를 가져오고, 점수화 하여 보여준다. 

반면, `mill lane` 을 모두 포함하고 싶은 경우에는 다음과 같이 진행한다. 

    curl -X GET "localhost:9200/bank/_search?pretty" \
    -H 'Content-Type: application/json' -d'
    {
      "query": { "match_phrase": { "address": "mill lane" } }
    }
    '
    
    # 결과
    '
    ...
        "max_score" : 9.507477,
        "hits" : [
          {
            "_index" : "bank",
            "_type" : "_doc",
            "_id" : "136",
            "_score" : 9.507477,
            "_source" : {
              "account_number" : 136,
              "balance" : 45801,
              "firstname" : "Winnie",
              "lastname" : "Holland",
              "age" : 38,
              "gender" : "M",
              "address" : "198 Mill Lane",
              "employer" : "Neteria",
    ...

이 경우, 정확히 맞는 단어를 포함해야 하는 경우로 보인다, 다음과 같은 경우는 아무것도 나오지 않는다

완벽하게 단어가 매칭 되어야 한다. 

    curl -X GET "localhost:9200/bank/_search?pretty" \
    -H 'Content-Type: application/json' -d'
    {
      "query": { "match_phrase": { "address": "mi lane" } }
    }
    
    # 결과
    ...
    "hits" : {
        "total" : {
          "value" : 0,
          "relation" : "eq"
        },
        "max_score" : null,
        "hits" : [ ]
      }...

보다 복잡한 쿼리를 진행하기 위해서는 `bool` 쿼리를 사용해야 한다. 

`bool` 을 사용하여 복수의 쿼리 조건을 합칠 수 있다. 

이를 활용하여 Boolean query에서는 다음 세가지 조건을 구사할 수 있다. (==query clause)

- required (`must`)
- desirable (`should`)
- undesirable (`must_not`)

위 query clause중 `must` 와 `should` 는 얼마나 잘 맞는지가 document의 relevance score에 영향을 미친다. 

`must_not` 은 `filter` 처럼 다뤄진다. 이 부분은 score에 영향을 미치지 않는다. 

예시)

    curl -X GET "localhost:9200/bank/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "query": {
        "bool": {
          "must": [
            { "match": { "age": "40" } }
          ],
          "must_not": [
            { "match": { "state": "ID" } }
          ]
        }
      }
    }
    '

`must_not` 이외에도, 명시적으로 필터의 속성을 이용 함으로서 포함하거나 불포함 하고자 하는 document를 정해줄 수 있다. 

    curl -X GET "localhost:9200/bank/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "query": {
        "bool": {
          "must": { "match_all": {} },
          "filter": {
            "range": {
              "balance": {
                "gte": 20000,
                "lte": 30000
              }
            }
          }
        }
      }
    }
    '

### aggregations

이 작업은, 공통된 요소로 묶어서 보는 요약본 같은 느낌이다. (집합)

예를 들어, How many account holders are in Texas?" or "What’s the average balance of accounts in Tennessee? 와 같은 질문을 던져볼 수 있다. 

terms 를 이용하여 다음과 같이 질의할 수 있다. 

    curl -X GET "localhost:9200/bank/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "size": 0,
      "aggs": {
        "group_by_state": {
          "terms": {
            "field": "state.keyword"
          }
        }
      }
    }
    '

이 경우에, 우리는 field중에 state의 값에 따라 group을 생성해 준다. 

위의 group_by_state는 namepix 정도로 생각하면 될듯 하다. 

    # 결과
    {
      "took" : 100,
      "timed_out" : false,
      "_shards" : {
        "total" : 1,
        "successful" : 1,
        "skipped" : 0,
        "failed" : 0
      },
      "hits" : {
        "total" : {
          "value" : 1000,
          "relation" : "eq"
        },
        "max_score" : null,
        "hits" : [ ]
      },
      "aggregations" : {
        "group_by_state" : {
          "doc_count_error_upper_bound" : 0,
          "sum_other_doc_count" : 743,
          "buckets" : [
            {
              "key" : "TX",
              "doc_count" : 30
            },
            {
              "key" : "MD",
              "doc_count" : 28
            },
            {
              "key" : "ID",
              "doc_count" : 27
            },
    ...

aggregation을 중첩하여 더 복잡한 요약본을 생성할 수도 있다 .

이 경우에는 주별 평균 계좌 잔고를 측정할 수 있다. 

    curl -X GET "localhost:9200/bank/_search?pretty" \
    -H 'Content-Type: application/json' -d'
    {
      "size": 0,
      "aggs": {
        "group_by_state": {
          "terms": {
            "field": "state.keyword"
          },
          "aggs": {
            "average_balance": {
              "avg": {
                "field": "balance"
              }
            }
          }
        }
      }
    }
    '

또, 다음과 같이 정렬도 가능하다. .

    curl -X GET "localhost:9200/bank/_search?pretty" -H 'Content-Type: application/json' -d'
    {
      "size": 0,
      "aggs": {
        "group_by_state": {
          "terms": {
            "field": "state.keyword",
            "order": {
              "average_balance": "desc"
            }
          },
          "aggs": {
            "average_balance": {
              "avg": {
                "field": "balance"
              }
            }
          }
        }
      }
    }
    '